{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "In notebook avm_singapore we build automated valuation models. In this notebook we will investigate if we can get better results by first clustering the properties and subsequently build an AVM model for the largest clusters of properties. We also build an AVM on all the data to fall back on when a property does not fit into any of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Let's first explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   log_price_psf            Project Name  Area (Sqft)  Type_Condominium  \\\n",
      "0       7.519692     STIRLING RESIDENCES          657                 0   \n",
      "1       7.290293          WHISTLER GRAND          614                 0   \n",
      "2       7.670895          MARGARET VILLE          463                 0   \n",
      "3       7.525101     STIRLING RESIDENCES         1346                 0   \n",
      "4       7.515889  AVENUE SOUTH RESIDENCE         1109                 0   \n",
      "\n",
      "   Relative_tenure  SaleType_Resale  SaleType_Sub Sale  Floor_number  \\\n",
      "0         0.914111                0                  0          23.0   \n",
      "1         0.915692                0                  0          18.0   \n",
      "2         0.914111                0                  0          38.0   \n",
      "3         0.914111                0                  0          23.0   \n",
      "4         0.915692                0                  0           8.0   \n",
      "\n",
      "   Market Segment_OCR  Market Segment_RCR  ...  Period_2017Q4  Period_2018Q1  \\\n",
      "0                   0                   1  ...              0              0   \n",
      "1                   1                   0  ...              0              0   \n",
      "2                   0                   1  ...              0              0   \n",
      "3                   0                   1  ...              0              0   \n",
      "4                   0                   1  ...              0              0   \n",
      "\n",
      "   Period_2018Q2  Period_2018Q3  Period_2018Q4  Period_2019Q1  Period_2019Q2  \\\n",
      "0              0              0              0              0              0   \n",
      "1              0              0              0              0              0   \n",
      "2              0              0              0              0              0   \n",
      "3              0              0              0              0              0   \n",
      "4              0              0              0              0              0   \n",
      "\n",
      "   Period_2019Q3  Period_2019Q4  Period_2020Q1  \n",
      "0              0              0              1  \n",
      "1              0              0              1  \n",
      "2              0              0              1  \n",
      "3              0              0              1  \n",
      "4              0              0              1  \n",
      "\n",
      "[5 rows x 46 columns] \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58143 entries, 0 to 58249\n",
      "Data columns (total 46 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   log_price_psf       58143 non-null  float64\n",
      " 1   Project Name        58143 non-null  object \n",
      " 2   Area (Sqft)         58143 non-null  int64  \n",
      " 3   Type_Condominium    58143 non-null  int64  \n",
      " 4   Relative_tenure     58143 non-null  float64\n",
      " 5   SaleType_Resale     58143 non-null  int64  \n",
      " 6   SaleType_Sub Sale   58143 non-null  int64  \n",
      " 7   Floor_number        58143 non-null  float64\n",
      " 8   Market Segment_OCR  58143 non-null  int64  \n",
      " 9   Market Segment_RCR  58143 non-null  int64  \n",
      " 10  District_1          58143 non-null  int64  \n",
      " 11  District_2          58143 non-null  int64  \n",
      " 12  District_4          58143 non-null  int64  \n",
      " 13  District_5          58143 non-null  int64  \n",
      " 14  District_8          58143 non-null  int64  \n",
      " 15  District_9          58143 non-null  int64  \n",
      " 16  District_10         58143 non-null  int64  \n",
      " 17  District_11         58143 non-null  int64  \n",
      " 18  District_12         58143 non-null  int64  \n",
      " 19  District_13         58143 non-null  int64  \n",
      " 20  District_14         58143 non-null  int64  \n",
      " 21  District_15         58143 non-null  int64  \n",
      " 22  District_16         58143 non-null  int64  \n",
      " 23  District_17         58143 non-null  int64  \n",
      " 24  District_18         58143 non-null  int64  \n",
      " 25  District_19         58143 non-null  int64  \n",
      " 26  District_20         58143 non-null  int64  \n",
      " 27  District_21         58143 non-null  int64  \n",
      " 28  District_22         58143 non-null  int64  \n",
      " 29  District_23         58143 non-null  int64  \n",
      " 30  District_27         58143 non-null  int64  \n",
      " 31  District_28         58143 non-null  int64  \n",
      " 32  District_other      58143 non-null  int64  \n",
      " 33  Period_2017Q1       58143 non-null  int64  \n",
      " 34  Period_2017Q2       58143 non-null  int64  \n",
      " 35  Period_2017Q3       58143 non-null  int64  \n",
      " 36  Period_2017Q4       58143 non-null  int64  \n",
      " 37  Period_2018Q1       58143 non-null  int64  \n",
      " 38  Period_2018Q2       58143 non-null  int64  \n",
      " 39  Period_2018Q3       58143 non-null  int64  \n",
      " 40  Period_2018Q4       58143 non-null  int64  \n",
      " 41  Period_2019Q1       58143 non-null  int64  \n",
      " 42  Period_2019Q2       58143 non-null  int64  \n",
      " 43  Period_2019Q3       58143 non-null  int64  \n",
      " 44  Period_2019Q4       58143 non-null  int64  \n",
      " 45  Period_2020Q1       58143 non-null  int64  \n",
      "dtypes: float64(3), int64(42), object(1)\n",
      "memory usage: 20.8+ MB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "df = pd.read_csv('datasets/ura_data_withproject.csv', index_col=0)\n",
    "print(df.head(), '\\n')\n",
    "print(df.info(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1', '2018Q2', '2018Q3', '2018Q4', '2019Q1', '2019Q2', '2019Q3', '2019Q4', '2020Q1']\n"
     ]
    }
   ],
   "source": [
    "y = df['log_price_psf']\n",
    "res = []\n",
    "per = ['%sQ%s' % (y,q) for y in range(2017,2021) for q in range(1,5)]\n",
    "per = per[:-3]\n",
    "print(per)\n",
    "min_obs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll build an model for the entire dataset. Afterwards we will cluster the data and build a model for each cluster. The models will be saved in the temp_files folder (make sure this folder exists before running the code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2017Q1 to 2018Q1\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...skipping cluster 2\n",
      "Working on 2017Q2 to 2018Q2\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...skipping cluster 2\n",
      "Working on 2017Q3 to 2018Q3\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...skipping cluster 2\n",
      "Working on 2017Q4 to 2018Q4\n",
      "...fitting overall\n",
      "...clustering\n",
      "...skipping cluster 0\n",
      "...fitting cluster 1\n",
      "...fitting cluster 2\n",
      "Working on 2018Q1 to 2019Q1\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...fitting cluster 2\n",
      "Working on 2018Q2 to 2019Q2\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...skipping cluster 2\n",
      "Working on 2018Q3 to 2019Q3\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...skipping cluster 2\n",
      "Working on 2018Q4 to 2019Q4\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...skipping cluster 2\n",
      "Working on 2019Q1 to 2020Q1\n",
      "...fitting overall\n",
      "...clustering\n",
      "...fitting cluster 0\n",
      "...fitting cluster 1\n",
      "...fitting cluster 2\n",
      "\n",
      "Finished: Models saved in temp_files folder\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for start in range(0,len(per)-5+1):\n",
    "    win = per[start:start+5]\n",
    "    print('Working on', win[0], 'to', win[-1])\n",
    "    fil = df['Period_%s' % win[0]] == 1\n",
    "    for i in [1,2,3,4]:\n",
    "        fil = fil | (df['Period_%s' % win[i]] ==1)\n",
    "    fil = copy.deepcopy(df[fil])\n",
    "    \n",
    "    # Fit overall model\n",
    "    print('...fitting overall')\n",
    "    y = fil['log_price_psf']\n",
    "    cols = [c for c in df.columns if not c.startswith('Period_') and not c in ['log_price_psf', 'Project Name']]\n",
    "    X = fil[cols]\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    mod = sm.OLS(y, X)\n",
    "    res = mod.fit()\n",
    "    res.save('temp_files/rolling_%s.pkl' % win[-1])\n",
    "    \n",
    "    # Cluster the data\n",
    "    print('...clustering')\n",
    "    cols = [c for c in df.columns if not c.startswith('Period_') and not c.startswith('District') and not c.startswith('Type') and not c.startswith('SaleType') and not c.startswith('Market Segment')]\n",
    "    # cols_std =\n",
    "    mean = fil.groupby('Project Name')[cols].mean()\n",
    "    mean.columns = ['%s_mean' % c for c in mean.columns]\n",
    "    std = fil.groupby('Project Name')[cols].std()\n",
    "    std.columns = ['%s_std' % c for c in std.columns]\n",
    "    std.fillna(0, inplace=True)\n",
    "    clus = pd.concat([mean, std], axis=1)\n",
    "    \n",
    "    ss = StandardScaler().fit_transform(clus)\n",
    "    ss = pd.DataFrame(ss, index=clus.index, columns=clus.columns)\n",
    "    \n",
    "    pca = PCA()\n",
    "    pca.fit_transform(ss)\n",
    "    red = PCA(n_components=5).fit_transform(ss)\n",
    "    \n",
    "    km = KMeans(n_clusters=3)\n",
    "    km.fit(red)\n",
    "    lab = km.predict(red)\n",
    "    ss['Cluster'] = lab\n",
    "    pickle.dump(ss['Cluster'], open('temp_files/K3_cluster_%s.pkl' % win[-1], 'wb'))\n",
    "    fil['Cluster'] = fil['Project Name'].apply(lambda x: ss.loc[x, 'Cluster'])\n",
    "    \n",
    "    # Fit one model for each cluster\n",
    "    clus_gr = fil.groupby('Cluster')\n",
    "    for c, d in clus_gr:\n",
    "        c = int(c)\n",
    "        if len(d) < min_obs:\n",
    "            print('...skipping cluster', c)\n",
    "        else:\n",
    "            print('...fitting cluster', c)\n",
    "            y = d['log_price_psf']\n",
    "            cols = [c for c in df.columns if not c.startswith('Period_') and not c in ['log_price_psf', 'Project Name']] + ['Period_%s' % p for p in per[1:5]]\n",
    "            X = d[cols]\n",
    "            X = sm.add_constant(X)\n",
    "            \n",
    "            mod = sm.OLS(y,X)\n",
    "            res = mod.fit()\n",
    "            res.save('temp_files/rolling_%s_K3_%s.pkl' % (win[-1], c))\n",
    "print('\\nFinished: Models saved in temp_files folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "[Work in progress]\n",
    "\n",
    "TODO: Calculate RMSE and compare results for the overall model with the specified models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
