{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "The goal of this notebook is to produce an automated valuation tool for Singapore. We make use of the data provided by the Urban Redevelopment Authority (URA) found in the dataset folder.\n",
    "\n",
    "We will build three different models and each time test their accuracy:\n",
    "- A hedonic regression model\n",
    "- An XGboost model\n",
    "- A random forest regression model\n",
    "\n",
    "Finally, we will combine these three models into an ensamble method and compare its accuracy to the accuracy of the individual models.\n",
    "\n",
    "TODO: Build an AVM tool that uses the model (see bottom). Potentially can be turned in a webapp.\n",
    "TODO: Clean up the code. This notebook is a colation of several seperate scripts and therefore repeats itself unnecessarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hedonic regression\n",
    "\n",
    "## Building the model\n",
    "We use the Ordinary Least Squares (OLS) api from Statsmodels to build a 5 quarter rolling hedonic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dataset = pd.read_csv('datasets/singapore_ura.csv', index_col = 0)\n",
    "y = dataset['log_price_psf']\n",
    "    \n",
    "results_series_list = []\n",
    "period_list = ['%sQ%s' % (year, qtr) for year in range(2017,2021) for qtr in range(1,5)]\n",
    "period_list = period_list[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...saved to sgp_rolling_2018Q1.pkl\n",
      "...saved to sgp_rolling_2018Q2.pkl\n",
      "...saved to sgp_rolling_2018Q3.pkl\n",
      "...saved to sgp_rolling_2018Q4.pkl\n",
      "...saved to sgp_rolling_2019Q1.pkl\n",
      "...saved to sgp_rolling_2019Q2.pkl\n",
      "...saved to sgp_rolling_2019Q3.pkl\n",
      "...saved to sgp_rolling_2019Q4.pkl\n",
      "...saved to sgp_rolling_2020Q1.pkl\n",
      "...saved to sgp_rolling_2020Q2.pkl\n",
      ">>>saved to sgp_rolling.csv\n"
     ]
    }
   ],
   "source": [
    "for start_index in range(0,len(period_list)+1-5):\n",
    "    window_period_list = period_list[start_index:start_index+5]\n",
    "\n",
    "    period_filter = dataset['Period_%s' % window_period_list[0]] == 1\n",
    "    for i in [1,2,3,4]:\n",
    "        period_filter = period_filter | (dataset['Period_%s' % window_period_list[i]] == 1)\n",
    "\n",
    "    y_target = y[period_filter]\n",
    "    X_target = dataset[period_filter]\n",
    "    X_columns = [c for c in dataset.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % period for period in window_period_list[1:5]]\n",
    "    X_target = X_target[X_columns]\n",
    "    X_target = sm.add_constant(X_target)\n",
    "\n",
    "    model = sm.OLS(y_target,X_target)\n",
    "    results = model.fit()\n",
    "\n",
    "    result_series = results.params\n",
    "    pvalue_series = results.pvalues\n",
    "    pvalue_series.index = ['pvalue_%s' % idx for idx in pvalue_series.index]\n",
    "    result_series = result_series.append(pvalue_series)\n",
    "    result_series = result_series.append(pd.Series([results.rsquared], index = ['rsquared']))\n",
    "    result_series = result_series.append(pd.Series([results.rsquared_adj], index = ['rsquared_adj']))\n",
    "    result_series = result_series.append(pd.Series([results.nobs], index = ['nobs']))\n",
    "\n",
    "    results_series_list.append(result_series)\n",
    "    results.save(\"temp_files/sgp_rolling_%s.pkl\" % window_period_list[-1])\n",
    "    print(\"...saved to sgp_rolling_%s.pkl\" % window_period_list[-1])\n",
    "\n",
    "results_df = pd.concat(results_series_list,axis = 1)\n",
    "results_df.columns = period_list[0:len(period_list)+1-5]\n",
    "results_df.to_csv('temp_files/sgp_rolling.csv')\n",
    "print(\"...saved to temp_files/sgp_rolling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...saved to temp_files/sgp_rolling_index.csv\n"
     ]
    }
   ],
   "source": [
    "index_dict = {}\n",
    "for start_index in range(0,len(period_list)+1-5):\n",
    "    window_period_list = period_list[start_index:start_index+5]\n",
    "    index_list = [100.0]\n",
    "    for i in [1,2,3,4]:\n",
    "        index_list.append(100.0 * np.exp(results_df[window_period_list[0]]['Period_%s' % window_period_list[i]]))    \n",
    "    index_dict[window_period_list[0]] = index_list\n",
    "\n",
    "final_index_list = []\n",
    "for period in sorted(index_dict.keys()):\n",
    "    if not len(final_index_list):\n",
    "        final_index_list = index_dict[period]\n",
    "    else:\n",
    "        new_index_value = index_dict[period][-1] * final_index_list[-1] / index_dict[period][-2]\n",
    "        final_index_list.append(new_index_value)\n",
    "\n",
    "final_index_df = pd.DataFrame(final_index_list, index = period_list, columns = ['Index'])\n",
    "final_index_df.to_csv('temp_files/sgp_rolling_index.csv')\n",
    "print(\"...saved to temp_files/sgp_rolling_index.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Testing accuracy\n",
    "We use the Mean Absolute Percentage Error (MAPE) and Median Absolute Percentage Error (MdAPE) to determine the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MdAPE: 9.3%\n",
      "MAPE: 12.1%\n",
      "MdAPE within 8.7%, 95% of the time\n",
      "MAPE within 10.4%, 95% of the time\n",
      "82.5% of predictions within 20% of observed values\n",
      "52.9% of predictions within 10% of observed values\n",
      "29.4% of predictions within 5% of observed values\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLSResults\n",
    "from copy import deepcopy\n",
    "\n",
    "df = pd.read_csv('datasets/singapore_ura.csv', index_col=0)\n",
    "\n",
    "per_ls = ['%sQ%s' % (yr, qtr) for yr in range(2017,2021) for qtr in range(1,5)]\n",
    "per_ls = per_ls[:-2]\n",
    "\n",
    "ape_ls = []\n",
    "for start in range(0, len(per_ls)-5):\n",
    "    window = per_ls[start:start+5]\n",
    "    last = window[-1]\n",
    "    out = per_ls[start+5]\n",
    "\n",
    "    test = deepcopy(df[df['Period_%s' % out] == 1])\n",
    "    test['Period_%s' % last] = 1\n",
    "    test['Period_%s' % out] = 0\n",
    "\n",
    "    cols = [c for c in test.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % x for x in window[1:]]\n",
    "\n",
    "    X = test[cols]\n",
    "    X = sm.add_constant(X, has_constant = 'add')\n",
    "\n",
    "    results = OLSResults.load('temp_files/sgp_rolling_%s.pkl' % last)\n",
    "    pred_psf = np.exp(results.predict(X))\n",
    "    act_psf = np.exp(test['log_price_psf'])\n",
    "\n",
    "    ape = np.abs(pred_psf - act_psf) / act_psf\n",
    "    ape = ape.to_frame()\n",
    "    ape['Period'] = out\n",
    "    ape_ls.append(ape)\n",
    "\n",
    "ape_df = pd.concat(ape_ls)\n",
    "\n",
    "MdAPE = ape_df[0].median()\n",
    "MAPE = ape_df[0].mean()\n",
    "\n",
    "ape95 = ape_df[0][ape_df[0] < ape_df[0].quantile(0.95)]\n",
    "MdAPE95 = ape95.median()\n",
    "MAPE95 = ape95.mean()\n",
    "\n",
    "pct_in_20 = (ape_df[0] < 0.2).sum() / ape_df[0].count()\n",
    "pct_in_10 = (ape_df[0] < 0.1).sum() / ape_df[0].count()\n",
    "pct_in_5 = (ape_df[0] < 0.05).sum() / ape_df[0].count()\n",
    "\n",
    "print('MdAPE: %.1f%%' % (MdAPE*100))\n",
    "print('MAPE: %.1f%%' % (MAPE*100))\n",
    "print('MdAPE within %.1f%%, 95%% of the time' % (MdAPE95*100))\n",
    "print('MAPE within %.1f%%, 95%% of the time' % (MAPE95*100))\n",
    "print('%0.1f%% of predictions within 20%% of observed values' % (100.0*pct_in_20))\n",
    "print('%0.1f%% of predictions within 10%% of observed values' % (100.0*pct_in_10))\n",
    "print('%0.1f%% of predictions within 5%% of observed values' % (100.0*pct_in_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. XGBoost\n",
    "\n",
    "## 2.1. Building the model\n",
    "We use the XGBRegressor api from xgboost to build a 5 quarter rolling xgboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...saved to temp_files/sgp_rolling_xgb_2018Q1.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2018Q2.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2018Q3.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2018Q4.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2019Q1.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2019Q2.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2019Q3.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2019Q4.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2020Q1.pkl\n",
      "...saved to temp_files/sgp_rolling_xgb_2020Q2.pkl\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "dataset = pd.read_csv('datasets/singapore_ura.csv', index_col = 0)\n",
    "y = dataset['log_price_psf']\n",
    "\n",
    "results_series_list = []\n",
    "period_list = ['%sQ%s' % (year, qtr) for year in range(2017,2021) for qtr in range(1,5)]\n",
    "period_list = period_list[:-2]\n",
    "\n",
    "for start_index in range(0,len(period_list)+1-5):\n",
    "    window_period_list = period_list[start_index:start_index+5]\n",
    "\n",
    "    period_filter = dataset['Period_%s' % window_period_list[0]] == 1\n",
    "    for i in [1,2,3,4]:\n",
    "        period_filter = period_filter | (dataset['Period_%s' % window_period_list[i]] == 1)\n",
    "\n",
    "    y_target = y[period_filter]\n",
    "    X_target = dataset[period_filter]\n",
    "    X_columns = [c for c in dataset.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % period for period in window_period_list[1:5]]\n",
    "    X_target = X_target[X_columns]\n",
    "\n",
    "    xg_reg = xgb.XGBRegressor()\n",
    "    xg_reg.fit(X_target, y_target)\n",
    "    pickle.dump(xg_reg, open('temp_files/sgp_rolling_xgb_%s.pkl' % window_period_list[-1], 'wb'))\n",
    "    print('...saved to temp_files/sgp_rolling_xgb_%s.pkl' % window_period_list[-1])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Testing accuracy\n",
    "We use the Mean Absolute Percentage Error (MAPE) and Median Absolute Percentage Error (MdAPE) to determine the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MdAPE: 6.4%\n",
      "MAPE: 9.1%\n",
      "MdAPE within 5.9%, 95% of the time\n",
      "MAPE within 7.7%, 95% of the time\n",
      "89.3% of predictions within 20% of observed values\n",
      "66.5% of predictions within 10% of observed values\n",
      "41.9% of predictions within 5% of observed values\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/singapore_ura.csv', index_col=0)\n",
    "\n",
    "per_ls = ['%sQ%s' % (yr, qtr) for yr in range(2017,2021) for qtr in range(1,5)]\n",
    "per_ls = per_ls[:-2]\n",
    "\n",
    "ape_ls = []\n",
    "for start in range(0, len(per_ls)-5):\n",
    "    window = per_ls[start:start+5]\n",
    "    last = window[-1]\n",
    "    out = per_ls[start+5]\n",
    "\n",
    "    test = deepcopy(df[df['Period_%s' % out] == 1])\n",
    "    test['Period_%s' % last] = 1\n",
    "    test['Period_%s' % out] = 0\n",
    "\n",
    "    cols = [c for c in test.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % x for x in window[1:]]\n",
    "    X = test[cols]\n",
    "\n",
    "    results = pickle.load(open('temp_files/sgp_rolling_xgb_%s.pkl' % last, 'rb'))\n",
    "    pred_psf = np.exp(results.predict(X))\n",
    "    act_psf = np.exp(test['log_price_psf'])\n",
    "\n",
    "    ape = np.abs(pred_psf - act_psf) / act_psf\n",
    "    ape = ape.to_frame()\n",
    "    ape['Period'] = out\n",
    "    ape_ls.append(ape)\n",
    "\n",
    "ape_df = pd.concat(ape_ls)\n",
    "ape_df.columns = [0, 'Period']\n",
    "\n",
    "MdAPE = ape_df[0].median()\n",
    "MAPE = ape_df[0].mean()\n",
    "\n",
    "ape95 = ape_df[0][ape_df[0] < ape_df[0].quantile(0.95)]\n",
    "MdAPE95 = ape95.median()\n",
    "MAPE95 = ape95.mean()\n",
    "\n",
    "pct_in_20 = (ape_df[0] < 0.2).sum() / ape_df[0].count()\n",
    "pct_in_10 = (ape_df[0] < 0.1).sum() / ape_df[0].count()\n",
    "pct_in_5 = (ape_df[0] < 0.05).sum() / ape_df[0].count()\n",
    "\n",
    "print('MdAPE: %.1f%%' % (MdAPE*100))\n",
    "print('MAPE: %.1f%%' % (MAPE*100))\n",
    "print('MdAPE within %.1f%%, 95%% of the time' % (MdAPE95*100))\n",
    "print('MAPE within %.1f%%, 95%% of the time' % (MAPE95*100))\n",
    "print('%0.1f%% of predictions within 20%% of observed values' % (100.0*pct_in_20))\n",
    "print('%0.1f%% of predictions within 10%% of observed values' % (100.0*pct_in_10))\n",
    "print('%0.1f%% of predictions within 5%% of observed values' % (100.0*pct_in_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random forrests regression\n",
    "\n",
    "## 3.1. Building the model\n",
    "We use the Random Forrest Regressor api from SKlearn to build a 5 quarter rolling random forrest regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...savend to temp_files/sgp_rolling_rf_2018Q1.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2018Q2.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2018Q3.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2018Q4.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2019Q1.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2019Q2.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2019Q3.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2019Q4.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2020Q1.pkl\n",
      "...savend to temp_files/sgp_rolling_rf_2020Q2.pkl\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble as sk\n",
    "\n",
    "dataset = pd.read_csv('datasets/singapore_ura.csv', index_col = 0)\n",
    "y = dataset['log_price_psf']\n",
    "\n",
    "results_series_list = []\n",
    "period_list = ['%sQ%s' % (year, qtr) for year in range(2017,2021) for qtr in range(1,5)]\n",
    "period_list = period_list[:-2]\n",
    "\n",
    "for start_index in range(0,len(period_list)+1-5):\n",
    "    window_period_list = period_list[start_index:start_index+5]\n",
    "\n",
    "    period_filter = dataset['Period_%s' % window_period_list[0]] == 1\n",
    "    for i in [1,2,3,4]:\n",
    "        period_filter = period_filter | (dataset['Period_%s' % window_period_list[i]] == 1)\n",
    "\n",
    "    y_target = y[period_filter]\n",
    "    X_target = dataset[period_filter]\n",
    "    X_columns = [c for c in dataset.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % period for period in window_period_list[1:5]]\n",
    "    X_target = X_target[X_columns]\n",
    "\n",
    "    rf_reg = sk.RandomForestRegressor()\n",
    "    rf_reg.fit(X_target, y_target)\n",
    "    pickle.dump(rf_reg, open('temp_files/sgp_rolling_rf_%s.pkl' % window_period_list[-1], 'wb'))\n",
    "    print('...savend to temp_files/sgp_rolling_rf_%s.pkl' % window_period_list[-1])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Testing accuracy\n",
    "We use the Mean Absolute Percentage Error (MAPE) and Median Absolute Percentage Error (MdAPE) to determine the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MdAPE: 5.6%\n",
      "MAPE: 9.0%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.4%, 95% of the time\n",
      "88.5% of predictions within 20% of observed values\n",
      "68.0% of predictions within 10% of observed values\n",
      "46.5% of predictions within 5% of observed values\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/singapore_ura.csv', index_col=0)\n",
    "\n",
    "per_ls = ['%sQ%s' % (yr, qtr) for yr in range(2017,2021) for qtr in range(1,5)]\n",
    "per_ls = per_ls[:-2]\n",
    "\n",
    "ape_ls = []\n",
    "for start in range(0, len(per_ls)-5):\n",
    "    window = per_ls[start:start+5]\n",
    "    last = window[-1]\n",
    "    out = per_ls[start+5]\n",
    "\n",
    "    test = deepcopy(df[df['Period_%s' % out] == 1])\n",
    "    test['Period_%s' % last] = 1\n",
    "    test['Period_%s' % out] = 0\n",
    "\n",
    "    cols = [c for c in test.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % x for x in window[1:]]\n",
    "    X = test[cols]\n",
    "\n",
    "    results = pickle.load(open('temp_files/sgp_rolling_rf_%s.pkl' % last, 'rb'))\n",
    "    pred_psf = np.exp(results.predict(X))\n",
    "    act_psf = np.exp(test['log_price_psf'])\n",
    "\n",
    "    ape = np.abs(pred_psf - act_psf) / act_psf\n",
    "    ape = ape.to_frame()\n",
    "    ape['Period'] = out\n",
    "    ape_ls.append(ape)\n",
    "\n",
    "ape_df = pd.concat(ape_ls)\n",
    "ape_df.columns = [0, 'Period']\n",
    "\n",
    "MdAPE = ape_df[0].median()\n",
    "MAPE = ape_df[0].mean()\n",
    "\n",
    "ape95 = ape_df[0][ape_df[0] < ape_df[0].quantile(0.95)]\n",
    "MdAPE95 = ape95.median()\n",
    "MAPE95 = ape95.mean()\n",
    "\n",
    "pct_in_20 = (ape_df[0] < 0.2).sum() / ape_df[0].count()\n",
    "pct_in_10 = (ape_df[0] < 0.1).sum() / ape_df[0].count()\n",
    "pct_in_5 = (ape_df[0] < 0.05).sum() / ape_df[0].count()\n",
    "\n",
    "print('MdAPE: %.1f%%' % (MdAPE*100))\n",
    "print('MAPE: %.1f%%' % (MAPE*100))\n",
    "print('MdAPE within %.1f%%, 95%% of the time' % (MdAPE95*100))\n",
    "print('MAPE within %.1f%%, 95%% of the time' % (MAPE95*100))\n",
    "print('%0.1f%% of predictions within 20%% of observed values' % (100.0*pct_in_20))\n",
    "print('%0.1f%% of predictions within 10%% of observed values' % (100.0*pct_in_10))\n",
    "print('%0.1f%% of predictions within 5%% of observed values' % (100.0*pct_in_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ensemble method\n",
    "\n",
    "## 4.1. Building the model\n",
    "It is clear that the XGBoost and Random Forest model outperform the Hedonic Regression model. Can we improve upon their individual scores by combining them? We will test this by making use of the SKlearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/singapore_ura.csv', index_col=0)\n",
    "\n",
    "per_ls = ['%sQ%s' % (yr, qtr) for yr in range(2017,2021) for qtr in range(1,5)]\n",
    "per_ls = per_ls[:-2]\n",
    "\n",
    "weights = [0, 0.23, 0.24, 0.25, 0.26, 0.27, 1]\n",
    "\n",
    "ape_dict = {}\n",
    "for w in weights:\n",
    "    ape_dict[w] = []\n",
    "\n",
    "ape_ls = []\n",
    "for start in range(0, len(per_ls)-5):\n",
    "    window = per_ls[start:start+5]\n",
    "    last = window[-1]\n",
    "    out = per_ls[start+5]\n",
    "\n",
    "    test = deepcopy(df[df['Period_%s' % out] == 1])\n",
    "    test['Period_%s' % last] = 1\n",
    "    test['Period_%s' % out] = 0\n",
    "\n",
    "    cols = [c for c in test.columns if not c.startswith('Period_') and not c in ['log_price_psf']] + ['Period_%s' % x for x in window[1:]]\n",
    "    X = test[cols]\n",
    "\n",
    "    xgb_results = pickle.load(open('temp_files/sgp_rolling_xgb_%s.pkl' % last, 'rb'))\n",
    "    xgb_pred_psf = np.exp(xgb_results.predict(X))\n",
    "\n",
    "    rf_results = pickle.load(open('temp_files/sgp_rolling_rf_%s.pkl' % last, 'rb'))\n",
    "    rf_pred_psf = np.exp(rf_results.predict(X))\n",
    "    act_psf = np.exp(test['log_price_psf'])\n",
    "\n",
    "    for w in weights:\n",
    "        pred_psf = w * xgb_pred_psf + (1.0-w) * rf_pred_psf\n",
    "\n",
    "        ape = np.abs(pred_psf - act_psf) / act_psf\n",
    "        ape = ape.to_frame()\n",
    "        ape['Period'] = out\n",
    "        ape.rename(columns={'log_price_psm':'ape'}, inplace=True)\n",
    "        \n",
    "        ape_dict[w].append(ape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Testing accuracy\n",
    "We use the Mean Absolute Percentage Error (MAPE) and Median Absolute Percentage Error (MdAPE) to determine the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  0\n",
      "MdAPE: 5.6%\n",
      "MAPE: 9.0%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.4%, 95% of the time\n",
      "88.5% of predictions within 20% of observed values\n",
      "68.0% of predictions within 10% of observed values\n",
      "46.5% of predictions within 5% of observed values\n",
      "-------------------------\n",
      "w:  0.23\n",
      "MdAPE: 5.6%\n",
      "MAPE: 8.7%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.2%, 95% of the time\n",
      "89.5% of predictions within 20% of observed values\n",
      "68.9% of predictions within 10% of observed values\n",
      "46.5% of predictions within 5% of observed values\n",
      "-------------------------\n",
      "w:  0.24\n",
      "MdAPE: 5.6%\n",
      "MAPE: 8.7%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.2%, 95% of the time\n",
      "89.5% of predictions within 20% of observed values\n",
      "68.9% of predictions within 10% of observed values\n",
      "46.4% of predictions within 5% of observed values\n",
      "-------------------------\n",
      "w:  0.25\n",
      "MdAPE: 5.6%\n",
      "MAPE: 8.7%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.2%, 95% of the time\n",
      "89.6% of predictions within 20% of observed values\n",
      "68.9% of predictions within 10% of observed values\n",
      "46.4% of predictions within 5% of observed values\n",
      "-------------------------\n",
      "w:  0.26\n",
      "MdAPE: 5.6%\n",
      "MAPE: 8.7%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.2%, 95% of the time\n",
      "89.6% of predictions within 20% of observed values\n",
      "69.0% of predictions within 10% of observed values\n",
      "46.4% of predictions within 5% of observed values\n",
      "-------------------------\n",
      "w:  0.27\n",
      "MdAPE: 5.7%\n",
      "MAPE: 8.7%\n",
      "MdAPE within 5.2%, 95% of the time\n",
      "MAPE within 7.2%, 95% of the time\n",
      "89.7% of predictions within 20% of observed values\n",
      "68.9% of predictions within 10% of observed values\n",
      "46.4% of predictions within 5% of observed values\n",
      "-------------------------\n",
      "w:  1\n",
      "MdAPE: 6.4%\n",
      "MAPE: 9.1%\n",
      "MdAPE within 5.9%, 95% of the time\n",
      "MAPE within 7.7%, 95% of the time\n",
      "89.3% of predictions within 20% of observed values\n",
      "66.5% of predictions within 10% of observed values\n",
      "41.9% of predictions within 5% of observed values\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for w in weights:\n",
    "    ape_df = pd.concat(ape_dict[w])\n",
    "    ape_df.columns = [0, 'Period']\n",
    "    \n",
    "    MdAPE = ape_df[0].median()\n",
    "    MAPE = ape_df[0].mean()\n",
    "    \n",
    "    ape95 = ape_df[0][ape_df[0] < ape_df[0].quantile(0.95)]\n",
    "    MdAPE95 = ape95.median()\n",
    "    MAPE95 = ape95.mean()\n",
    "    \n",
    "    pct_in_20 = (ape_df[0] < 0.2).sum() / ape_df[0].count()\n",
    "    pct_in_10 = (ape_df[0] < 0.1).sum() / ape_df[0].count()\n",
    "    pct_in_5 = (ape_df[0] < 0.05).sum() / ape_df[0].count()\n",
    "    \n",
    "    print('w: ', w)\n",
    "    print('MdAPE: %.1f%%' % (MdAPE*100))\n",
    "    print('MAPE: %.1f%%' % (MAPE*100))\n",
    "    print('MdAPE within %.1f%%, 95%% of the time' % (MdAPE95*100))\n",
    "    print('MAPE within %.1f%%, 95%% of the time' % (MAPE95*100))\n",
    "    print('%0.1f%% of predictions within 20%% of observed values' % (100.0*pct_in_20))\n",
    "    print('%0.1f%% of predictions within 10%% of observed values' % (100.0*pct_in_10))\n",
    "    print('%0.1f%% of predictions within 5%% of observed values' % (100.0*pct_in_5))\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Unsurprisingly XGBoost and Random Forrest outperformed Hedonic Regression. However, less expected is that Random Forrest slightly outperformed XGBoost and that an ensemble method of the two only improved marginally on the Random Forrest model.\n",
    "\n",
    "Our best performing model is therefore the ensemble model made up of a 24% contribution from XGBoost model and a 76% contribution from Random Forrest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVM\n",
    "\n",
    "Fill in the parameters of your property below and run the cell. A predicted value for your property will be returned, based on the ensamble model described above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
